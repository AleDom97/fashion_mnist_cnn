{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"MhoQ0WE77laV"},"source":["##### Copyright 2018 The TensorFlow Authors."]},{"cell_type":"markdown","metadata":{"id":"jYysdyb-CaWM"},"source":["# Basic classification: Classify images of clothing"]},{"cell_type":"markdown","metadata":{"id":"FbVhjPpzn6BM"},"source":["This guide trains a neural network model to classify images of clothing, like sneakers and shirts. It's okay if you don't understand all the details; this is a fast-paced overview of a complete TensorFlow program with the details explained as you go.\n","\n","This guide uses [tf.keras](https://www.tensorflow.org/guide/keras), a high-level API to build and train models in TensorFlow."]},{"cell_type":"code","metadata":{"id":"dzLKpmZICaWN"},"source":["# TensorFlow and tf.keras\n","import tensorflow as tf\n","from tensorflow import keras\n","\n","# Helper libraries\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","print(tf.__version__)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yR0EdgrLCaWR"},"source":["## Import the Fashion MNIST dataset"]},{"cell_type":"code","metadata":{"id":"7MqDQO0KCaWS"},"source":["#TO DO : download dataset (training and testing)\n","fashion_mnist = tf.keras.datasets.fashion_mnist\n","\n","(train_images, train_labels), (test_images, test_labels)= fashion_mnist.load_data()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kCIqkrratP5V"},"source":[]},{"cell_type":"markdown","metadata":{"id":"t9FDsUlxCaWW"},"source":["Loading the dataset returns four NumPy arrays:\n","\n","* The `train_images` and `train_labels` arrays are the *training set*—the data the model uses to learn.\n","* The model is tested against the *test set*, the `test_images`, and `test_labels` arrays.\n","\n","The images are 28x28 NumPy arrays, with pixel values ranging from 0 to 255. The *labels* are an array of integers, ranging from 0 to 9. These correspond to the *class* of clothing the image represents:\n","\n","<table>\n","  <tr>\n","    <th>Label</th>\n","    <th>Class</th>\n","  </tr>\n","  <tr>\n","    <td>0</td>\n","    <td>T-shirt/top</td>\n","  </tr>\n","  <tr>\n","    <td>1</td>\n","    <td>Trouser</td>\n","  </tr>\n","    <tr>\n","    <td>2</td>\n","    <td>Pullover</td>\n","  </tr>\n","    <tr>\n","    <td>3</td>\n","    <td>Dress</td>\n","  </tr>\n","    <tr>\n","    <td>4</td>\n","    <td>Coat</td>\n","  </tr>\n","    <tr>\n","    <td>5</td>\n","    <td>Sandal</td>\n","  </tr>\n","    <tr>\n","    <td>6</td>\n","    <td>Shirt</td>\n","  </tr>\n","    <tr>\n","    <td>7</td>\n","    <td>Sneaker</td>\n","  </tr>\n","    <tr>\n","    <td>8</td>\n","    <td>Bag</td>\n","  </tr>\n","    <tr>\n","    <td>9</td>\n","    <td>Ankle boot</td>\n","  </tr>\n","</table>\n","\n","Each image is mapped to a single label. Since the *class names* are not included with the dataset, store them here to use later when plotting the images:"]},{"cell_type":"code","metadata":{"id":"IjnLH5S2CaWx"},"source":["class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n","               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Brm0b_KACaWX"},"source":["## Explore the data\n"]},{"cell_type":"code","metadata":{"id":"zW5k_xz1CaWX"},"source":["#TO DO: training shape\n","train_images.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TRFYHB2mCaWb"},"source":["#TO DO : count training labels\n","len(train_labels)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XKnCTHz4CaWg"},"source":["#TO DO : look at the training labels\n","train_labels"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2KFnYlcwCaWl"},"source":["#TO DO : testing shape\n","test_images.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iJmPr5-ACaWn"},"source":["#TO DO :  count testing labels\n","len(test_labels)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ES6uQoLKCaWr"},"source":["## Preprocess the data\n","\n","The data must be preprocessed before training the network. If you inspect the first image in the training set, you will see that the pixel values fall in the range of 0 to 255:"]},{"cell_type":"code","metadata":{"id":"m4VEw8Ud9Quh"},"source":["#plot an image\n","plt.figure()\n","plt.imshow(train_images[0], cmap = \"binary\")\n","plt.colorbar()\n","plt.grid(False)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Wz7l27Lz9S1P"},"source":["Scale these values to a range of 0 to 1 before feeding them to the neural network model. To do so, divide the values by 255. It's important that the *training set* and the *testing set* be preprocessed in the same way:"]},{"cell_type":"code","metadata":{"id":"bW5WzIPlCaWv"},"source":["# TO DO : normalization\n","train_images = train_images / 255.0\n","\n","test_images = test_images / 255.0"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ee638AlnCaWz"},"source":["To verify that the data is in the correct format and that you're ready to build and train the network, let's display the first 25 images from the *training set* and display the class name below each image."]},{"cell_type":"code","metadata":{"id":"oZTImqg_CaW1"},"source":["plt.figure(figsize=(10,10))\n","for i in range(25):\n","    plt.subplot(5,5,i+1)\n","    plt.xticks([])\n","    plt.yticks([])\n","    plt.grid(False)\n","    plt.imshow(train_images[i], cmap=plt.cm.binary)\n","    plt.xlabel(class_names[train_labels[i]])\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"59veuiEZCaW4"},"source":["## Build the model\n","\n","Building the neural network requires configuring the layers of the model, then compiling the model."]},{"cell_type":"markdown","metadata":{"id":"Gxg1XGm0eOBy"},"source":["### Set up the layers\n","\n"]},{"cell_type":"code","metadata":{"id":"9ODch-OFCaW4"},"source":["#TO DO: create the model 1\n","model = tf.keras.Sequential()\n","\n","model.add(tf.keras.layers.Conv2D(filters=64,kernel_size=2,strides=(1,1),padding=\"valid\",activation=\"relu\",input_shape=(28,28,1)))\n","model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n","model.add(tf.keras.layers.Dropout(0.3))\n","\n","model.add(tf.keras.layers.Conv2D(filters=32,kernel_size=2,strides=(1,1),padding=\"valid\",activation=\"relu\"))\n","model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n","model.add(tf.keras.layers.Dropout(0.3))\n","\n","model.add(tf.keras.layers.Flatten())\n","model.add(tf.keras.layers.Dense(256, activation=\"relu\"))\n","model.add(tf.keras.layers.Dropout(0.5))\n","model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#TO DO: create the model 2\n","model = tf.keras.Sequential()\n","# Per il primo livello inserisco 64 filtri di dimensione 3x3 con stride 1, cioè il filtro viene traslato di un passo alla volta.\n","# Inserendo padding = \"same\" si specifica la presenza di padding per fare in modo che l'output abbia la stessa dimensione dell'input\n","# Lavorando con immagini di dimensione 28x28x1, la stessa dimensione andrà impostata sul parametro input_shape\n","model.add(tf.keras.layers.Conv2D(filters=64,kernel_size=(3,3),strides=(1,1),padding=\"same\",activation=\"relu\",input_shape=(28,28,1)))\n","# Si ottiene il valore massimo in una finestra di 2x2 riducendo la dimensione del risultato prodotto dal precedente livello\n","model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n","# Imposto a 0 il 30% degli output che escono dal precedente livello per evitare overfitting della rete\n","model.add(tf.keras.layers.Dropout(0.3))\n","\n","# Aggiungo un nuovo \"blocco\" ma questa volta il livello convolutivo ha 32 filtri\n","model.add(tf.keras.layers.Conv2D(filters=32,kernel_size=(3,3),strides=(1,1),padding=\"same\",activation=\"relu\"))\n","model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n","model.add(tf.keras.layers.Dropout(0.3))\n","\n","# \"Appiattisco\" il risultato per passare da 2 dimensioni ad 1\n","model.add(tf.keras.layers.Flatten())\n","# Parte MLP della rete, aggiungo un livello fully connected con 256 neuroni e funzione d'attivazione relu\n","model.add(tf.keras.layers.Dense(256, activation=\"relu\"))\n","model.add(tf.keras.layers.Dropout(0.5))\n","# Per l'ultimo livello saranno necessari 10 neuroni, uno per ogni classe, e funzione di attivazione softmax\n","model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))"],"metadata":{"id":"oJBWW9KengH7"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EHQbRu1TGq93"},"source":["# TO DO: Take a look at the model summary\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gut8A_7rCaW6"},"source":["\n","### Compile the model\n","\n"]},{"cell_type":"code","metadata":{"id":"Lhan11blCaW7"},"source":["#TO DO: configure the learning process\n","model.compile(optimizer= \"adam\",\n","              loss=\"sparse_categorical_crossentropy\",\n","              metrics= [\"accuracy\"])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Z4P4zIV7E28Z"},"source":["### Train the model\n","\n"]},{"cell_type":"code","metadata":{"id":"xvwvpA64CaW_"},"source":["# TO DO: reshape the dataset according to the input format required by keras\n","train_images= train_images.reshape(train_images.shape[0],28,28,1)\n","test_images= test_images.reshape(test_images.shape[0],28,28,1)\n","\n","print(train_images.shape)\n","print(test_images.shape)\n","# TO DO : train the model\n","#history = model.fit(train_images, train_labels, batch_size=32, epochs=10)\n","history = model.fit(train_images, train_labels, epochs = 50, batch_size=32, validation_split = 0.2, verbose=1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wCpr6DGyE28h"},"source":["### Evaluate accuracy\n","\n","Next, compare how the model performs on the test dataset:"]},{"cell_type":"code","metadata":{"id":"VflXLEeECaXC"},"source":["#TO DO : test the model\n","test_loss, test_acc =model.evaluate(test_images, test_labels, verbose=1)\n","\n","print(\"accuracy in testing: \", test_acc)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"v-PyD1SYE28q"},"source":["### Make predictions\n","\n"]},{"cell_type":"code","source":["#plot an image\n","plt.figure()\n","plt.imshow(test_images[10], cmap = \"binary\")\n","plt.colorbar()\n","plt.grid(False)\n","plt.show()"],"metadata":{"id":"Zn5pf7KNiQHQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WvSWRbGxDeoD"},"source":["#TO DO: single prediction\n","predictions_single = model.predict(np.expand_dims(test_images[10],0))\n","\n","print(predictions_single)\n","np.argmax(predictions_single)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TW3FmfrpCgJF"},"source":["#TO DO : make predictions for each image in the test set\n","predictions = model.predict(test_images)\n","print(predictions)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"x9Kk1voUCaXJ"},"source":["Here, the model has predicted the label for each image in the testing set. Let's take a look at the first prediction:"]},{"cell_type":"code","metadata":{"id":"3DmJEUinCaXK"},"source":["predictions[10]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-hw1hgeSCaXN"},"source":["A prediction is an array of 10 numbers. They represent the model's \"confidence\" that the image corresponds to each of the 10 different articles of clothing. You can see which label has the highest confidence value:"]},{"cell_type":"code","metadata":{"id":"qsqenuPnCaXO"},"source":["np.argmax(predictions[10])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"E51yS7iCCaXO"},"source":["So, the model is most confident that this image is an ankle boot, or `class_names[9]`. Examining the test label shows that this classification is correct:"]},{"cell_type":"code","metadata":{"id":"Sd7Pgsu6CaXP"},"source":["test_labels[10]"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["classes_x=np.argmax(predictions,axis=1)"],"metadata":{"id":"4vUySwCZrJv7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["classes_x"],"metadata":{"id":"LJX3HeS0kN0U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["labels = {0 : \"T-shirt/top\", 1: \"Trouser\", 2: \"Pullover\", 3: \"Dress\", 4: \"Coat\", 5: \"Sandal\", 6: \"Shirt\", 7: \"Sneaker\", 8: \"Bag\", 9: \"Ankle Boot\"}\n","target_names = [\"Classe {} ({}) :\".format(i,labels[i]) for i in range(10)]"],"metadata":{"id":"V9ykoCJrkWzt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import classification_report, confusion_matrix"],"metadata":{"id":"3gXBt4gOktCT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(classification_report(test_labels, classes_x, target_names = target_names))"],"metadata":{"id":"Z_mO_bmtkYFf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.style.use('ggplot')\n","def plot_history(history):\n","    acc = history.history['accuracy']\n","    val_accuracy = history.history['val_accuracy']\n","    loss = history.history['loss']\n","    val_loss = history.history['val_loss']\n","    x = range(1, len(acc) + 1)\n","    plt.figure(figsize=(12, 5), dpi = 130)\n","    plt.subplot(1, 2, 1)\n","    plt.plot(x, acc, 'b', label='Training acc')\n","    plt.plot(x, val_accuracy, 'r', label='Validation acc')\n","    plt.title('Accuracy durante il training e validation')\n","    plt.xlabel('Numero di epoche')\n","    plt.ylabel('Accuratezza')\n","    plt.legend()\n","    plt.subplot(1, 2, 2)\n","    plt.plot(x, loss, 'b', label='Training loss')\n","    plt.plot(x, val_loss, 'r', label='Validation loss')\n","    plt.title('Loss durante il training e validation')\n","    plt.xlabel('Numero di epoche')\n","    plt.ylabel('Loss')\n","    plt.legend()\n","    plt.show()"],"metadata":{"id":"Ro8pfDmQlHmZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_history(history)"],"metadata":{"id":"cW-ZdCiUmEOz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cm=confusion_matrix(test_labels,classes_x)\n","print(cm)"],"metadata":{"id":"Jq_lSPWErHBX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ukTQx00bELTy"},"source":["### Visualization\n","\n"]},{"cell_type":"code","metadata":{"id":"jRiva3qcEoC0"},"source":["model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lxEv8LfqE5CI"},"source":["model.layers"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"V4G3Rp0xEqs6"},"source":["#TO DO : print the name and shape of the conv layers\n","# summarize feature map shapes\n","for i in range(len(model.layers)):\n","    layer= model.layers[i]\n","    #check for conv layer\n","    if \"conv\" not in layer.name:\n","      continue\n","    print(i, layer.name, layer.output.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RvR_uULuEmVk"},"source":["#TO DO : create a new model using layers from the previous model\n","# redefine model to output right after the first hidden layer\n","model_v = tf.keras.Model(inputs = model.inputs, outputs = model.layers[0].output)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qEtHQ84MFAut"},"source":["#TO DO: get the feature maps for an images\n","feature_maps = model_v.predict(train_images[1].reshape(1,28,28,1))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TeTYB571FE2_"},"source":["feature_maps.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ehP89OluFIrS"},"source":["#TO DO : plot the feature maps\n","\n","fig = plt.figure(figsize=(8,8))\n","\n","for i in range(64):\n","  sub = fig.add_subplot(8,8, i+1)\n","  sub.imshow(feature_maps[0,:,:,i], cmap = \"gray\")\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YzuB4j80FMv4"},"source":["#TO DO : repeat the above process using the second conv layer in our initial model\n","# redefine model to output right after the second conv  layer\n","model_v_3 = tf.keras.Model(inputs = model.inputs, outputs = model.layers[3].output)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"z0VC-I9HFRc3"},"source":["# TO DO : get the feature maps\n","feature_maps_3 = model_v.predict(train_images[1].reshape(1,28,28,1))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"L9qz0s4TFXIh"},"source":["#feature_maps_3[0][0]\n","feature_maps_3.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_ZB1OfJbFaX7"},"source":["#TO DO : plot the featue maps\n","fig = plt.figure(figsize=(8,8))\n","\n","for i in range(32):\n","  sub = fig.add_subplot(8,8, i+1)\n","  sub.imshow(feature_maps[0,:,:,i], cmap = \"gray\")"],"execution_count":null,"outputs":[]}]}