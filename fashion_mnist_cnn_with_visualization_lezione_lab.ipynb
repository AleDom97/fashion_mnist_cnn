{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYysdyb-CaWM"
      },
      "source": [
        "# Basic classification: Classify images of clothing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbVhjPpzn6BM"
      },
      "source": [
        "Training a neural network model to classify images of clothing, like sneakers and shirts."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzLKpmZICaWN"
      },
      "source": [
        "# TensorFlow and tf.keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Helper libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yR0EdgrLCaWR"
      },
      "source": [
        "## Import the Fashion MNIST dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MqDQO0KCaWS"
      },
      "source": [
        "#TO DO : download dataset (training and testing)\n",
        "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels)= fashion_mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCIqkrratP5V"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9FDsUlxCaWW"
      },
      "source": [
        "Loading the dataset returns four NumPy arrays:\n",
        "\n",
        "* The `train_images` and `train_labels` arrays are the *training set*â€”the data the model uses to learn.\n",
        "* The model is tested against the *test set*, the `test_images`, and `test_labels` arrays.\n",
        "\n",
        "The images are 28x28 NumPy arrays, with pixel values ranging from 0 to 255. The *labels* are an array of integers, ranging from 0 to 9. These correspond to the *class* of clothing the image represents:\n",
        "\n",
        "<table>\n",
        "  <tr>\n",
        "    <th>Label</th>\n",
        "    <th>Class</th>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>0</td>\n",
        "    <td>T-shirt/top</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>1</td>\n",
        "    <td>Trouser</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>2</td>\n",
        "    <td>Pullover</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>3</td>\n",
        "    <td>Dress</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>4</td>\n",
        "    <td>Coat</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>5</td>\n",
        "    <td>Sandal</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>6</td>\n",
        "    <td>Shirt</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>7</td>\n",
        "    <td>Sneaker</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>8</td>\n",
        "    <td>Bag</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>9</td>\n",
        "    <td>Ankle boot</td>\n",
        "  </tr>\n",
        "</table>\n",
        "\n",
        "Each image is mapped to a single label. Since the *class names* are not included with the dataset, store them here to use later when plotting the images:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjnLH5S2CaWx"
      },
      "source": [
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Brm0b_KACaWX"
      },
      "source": [
        "## Explore the data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zW5k_xz1CaWX"
      },
      "source": [
        "#TO DO: training shape\n",
        "train_images.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRFYHB2mCaWb"
      },
      "source": [
        "#TO DO : count training labels\n",
        "len(train_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKnCTHz4CaWg"
      },
      "source": [
        "#TO DO : look at the training labels\n",
        "train_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2KFnYlcwCaWl"
      },
      "source": [
        "#TO DO : testing shape\n",
        "test_images.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJmPr5-ACaWn"
      },
      "source": [
        "#TO DO :  count testing labels\n",
        "len(test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ES6uQoLKCaWr"
      },
      "source": [
        "## Preprocess the data\n",
        "\n",
        "The data must be preprocessed before training the network. If you inspect the first image in the training set, you will see that the pixel values fall in the range of 0 to 255:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4VEw8Ud9Quh"
      },
      "source": [
        "#plot an image\n",
        "plt.figure()\n",
        "plt.imshow(train_images[0], cmap = \"binary\")\n",
        "plt.colorbar()\n",
        "plt.grid(False)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wz7l27Lz9S1P"
      },
      "source": [
        "Scale these values to a range of 0 to 1 before feeding them to the neural network model. To do so, divide the values by 255. It's important that the *training set* and the *testing set* be preprocessed in the same way:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bW5WzIPlCaWv"
      },
      "source": [
        "# TO DO : normalization\n",
        "train_images = train_images / 255.0\n",
        "\n",
        "test_images = test_images / 255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ee638AlnCaWz"
      },
      "source": [
        "To verify that the data is in the correct format and that you're ready to build and train the network, let's display the first 25 images from the *training set* and display the class name below each image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZTImqg_CaW1"
      },
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(train_images[i], cmap=plt.cm.binary)\n",
        "    plt.xlabel(class_names[train_labels[i]])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59veuiEZCaW4"
      },
      "source": [
        "## Build the model\n",
        "\n",
        "Building the neural network requires configuring the layers of the model, then compiling the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gxg1XGm0eOBy"
      },
      "source": [
        "### Set up the layers\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ODch-OFCaW4"
      },
      "source": [
        "#TO DO: create the model 1\n",
        "model = tf.keras.Sequential()\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(filters=64,kernel_size=2,strides=(1,1),padding=\"valid\",activation=\"relu\",input_shape=(28,28,1)))\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
        "model.add(tf.keras.layers.Dropout(0.3))\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(filters=32,kernel_size=2,strides=(1,1),padding=\"valid\",activation=\"relu\"))\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
        "model.add(tf.keras.layers.Dropout(0.3))\n",
        "\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(256, activation=\"relu\"))\n",
        "model.add(tf.keras.layers.Dropout(0.5))\n",
        "model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TO DO: create the model 2\n",
        "model = tf.keras.Sequential()\n",
        "# For the first level I insert 64 filters of size 3x3 with stride 1, i.e. the filter is translated one step at a time.\n",
        "# By entering padding = \"same\" you specify the presence of padding to ensure that the output has the same size as the input\n",
        "# When working with images of size 28x28x1, the same size must be set on the input_shape parameter\n",
        "model.add(tf.keras.layers.Conv2D(filters=64,kernel_size=(3,3),strides=(1,1),padding=\"same\",activation=\"relu\",input_shape=(28,28,1)))\n",
        "# The maximum value in a 2x2 window is obtained by reducing the size of the result produced by the previous level\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
        "# Set to 0 30% of the outputs that leave the previous level to avoid overfitting the network\n",
        "model.add(tf.keras.layers.Dropout(0.3))\n",
        "\n",
        "# I add a new \"block\" but this time the convolutional layer has 32 filters\n",
        "model.add(tf.keras.layers.Conv2D(filters=32,kernel_size=(3,3),strides=(1,1),padding=\"same\",activation=\"relu\"))\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
        "model.add(tf.keras.layers.Dropout(0.3))\n",
        "\n",
        "# I \"flatten\" the result to go from 2 dimensions to 1\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "# MLP part of the network, I add a fully connected layer with 256 neurons and relu activation function\n",
        "model.add(tf.keras.layers.Dense(256, activation=\"relu\"))\n",
        "model.add(tf.keras.layers.Dropout(0.5))\n",
        "# For the last level you will need 10 neurons, one for each class, and softmax activation function\n",
        "model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))"
      ],
      "metadata": {
        "id": "oJBWW9KengH7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHQbRu1TGq93"
      },
      "source": [
        "# TO DO: Take a look at the model summary\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gut8A_7rCaW6"
      },
      "source": [
        "\n",
        "### Compile the model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lhan11blCaW7"
      },
      "source": [
        "#TO DO: configure the learning process\n",
        "model.compile(optimizer= \"adam\",\n",
        "              loss=\"sparse_categorical_crossentropy\",\n",
        "              metrics= [\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4P4zIV7E28Z"
      },
      "source": [
        "### Train the model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvwvpA64CaW_"
      },
      "source": [
        "# TO DO: reshape the dataset according to the input format required by keras\n",
        "train_images= train_images.reshape(train_images.shape[0],28,28,1)\n",
        "test_images= test_images.reshape(test_images.shape[0],28,28,1)\n",
        "\n",
        "print(train_images.shape)\n",
        "print(test_images.shape)\n",
        "# TO DO : train the model\n",
        "#history = model.fit(train_images, train_labels, batch_size=32, epochs=10)\n",
        "history = model.fit(train_images, train_labels, epochs = 50, batch_size=32, validation_split = 0.2, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCpr6DGyE28h"
      },
      "source": [
        "### Evaluate accuracy\n",
        "\n",
        "Next, compare how the model performs on the test dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VflXLEeECaXC"
      },
      "source": [
        "#TO DO : test the model\n",
        "test_loss, test_acc =model.evaluate(test_images, test_labels, verbose=1)\n",
        "\n",
        "print(\"accuracy in testing: \", test_acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-PyD1SYE28q"
      },
      "source": [
        "### Make predictions\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#plot an image\n",
        "plt.figure()\n",
        "plt.imshow(test_images[10], cmap = \"binary\")\n",
        "plt.colorbar()\n",
        "plt.grid(False)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Zn5pf7KNiQHQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvSWRbGxDeoD"
      },
      "source": [
        "#TO DO: single prediction\n",
        "predictions_single = model.predict(np.expand_dims(test_images[10],0))\n",
        "\n",
        "print(predictions_single)\n",
        "np.argmax(predictions_single)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TW3FmfrpCgJF"
      },
      "source": [
        "#TO DO : make predictions for each image in the test set\n",
        "predictions = model.predict(test_images)\n",
        "print(predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9Kk1voUCaXJ"
      },
      "source": [
        "Here, the model has predicted the label for each image in the testing set. Let's take a look at the first prediction:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DmJEUinCaXK"
      },
      "source": [
        "predictions[10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hw1hgeSCaXN"
      },
      "source": [
        "A prediction is an array of 10 numbers. They represent the model's \"confidence\" that the image corresponds to each of the 10 different articles of clothing. You can see which label has the highest confidence value:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsqenuPnCaXO"
      },
      "source": [
        "np.argmax(predictions[10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E51yS7iCCaXO"
      },
      "source": [
        "So, the model is most confident that this image is an ankle boot, or `class_names[9]`. Examining the test label shows that this classification is correct:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sd7Pgsu6CaXP"
      },
      "source": [
        "test_labels[10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes_x=np.argmax(predictions,axis=1)"
      ],
      "metadata": {
        "id": "4vUySwCZrJv7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes_x"
      ],
      "metadata": {
        "id": "LJX3HeS0kN0U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = {0 : \"T-shirt/top\", 1: \"Trouser\", 2: \"Pullover\", 3: \"Dress\", 4: \"Coat\", 5: \"Sandal\", 6: \"Shirt\", 7: \"Sneaker\", 8: \"Bag\", 9: \"Ankle Boot\"}\n",
        "target_names = [\"Classe {} ({}) :\".format(i,labels[i]) for i in range(10)]"
      ],
      "metadata": {
        "id": "V9ykoCJrkWzt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix"
      ],
      "metadata": {
        "id": "3gXBt4gOktCT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(test_labels, classes_x, target_names = target_names))"
      ],
      "metadata": {
        "id": "Z_mO_bmtkYFf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.style.use('ggplot')\n",
        "def plot_history(history):\n",
        "    acc = history.history['accuracy']\n",
        "    val_accuracy = history.history['val_accuracy']\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "    x = range(1, len(acc) + 1)\n",
        "    plt.figure(figsize=(12, 5), dpi = 130)\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(x, acc, 'b', label='Training acc')\n",
        "    plt.plot(x, val_accuracy, 'r', label='Validation acc')\n",
        "    plt.title('Accuracy durante il training e validation')\n",
        "    plt.xlabel('Numero di epoche')\n",
        "    plt.ylabel('Accuratezza')\n",
        "    plt.legend()\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(x, loss, 'b', label='Training loss')\n",
        "    plt.plot(x, val_loss, 'r', label='Validation loss')\n",
        "    plt.title('Loss durante il training e validation')\n",
        "    plt.xlabel('Numero di epoche')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "Ro8pfDmQlHmZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_history(history)"
      ],
      "metadata": {
        "id": "cW-ZdCiUmEOz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm=confusion_matrix(test_labels,classes_x)\n",
        "print(cm)"
      ],
      "metadata": {
        "id": "Jq_lSPWErHBX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}